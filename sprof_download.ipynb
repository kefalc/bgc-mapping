{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bf3b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5netcdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcmocean\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetCDF4\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5netcdf\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Base filepath\u001b[39;00m\n\u001b[1;32m     24\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/kristenfalcinelli/Documents/Grad School/Research Materials/Mapping/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5netcdf'"
     ]
    }
   ],
   "source": [
    "#This code can be used to download Sprof files from the ARGO GDAC\n",
    "\n",
    "#Set up\n",
    "\n",
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import urllib3\n",
    "import shutil\n",
    "import plotly.graph_objects as go\n",
    "import cmocean\n",
    "import netCDF4\n",
    "import h5netcdf\n",
    "\n",
    "# Base filepath\n",
    "root = '/Users/kristenfalcinelli/Documents/Grad School/Research Materials/Mapping/'\n",
    "profile_dir = root + 'Profiles/'\n",
    "natl_dir = profile_dir + 'Test_Data_BGC/'#Change this for other projects\n",
    "\n",
    "# Create GO-BGC folders if they do not exist yet\n",
    "if 'Profiles' not in os.listdir(root):\n",
    "  os.mkdir(profile_dir)\n",
    "if 'Test_Data_BGC' not in os.listdir(profile_dir): #Change this for other projects\n",
    "  os.mkdir(natl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c280c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download a single file\n",
    "def download_file(url_path,filename,save_to=None,overwrite=False,verbose=True):\n",
    "    \"\"\" Downloads and saves a file from a given URL using HTTP protocol.\n",
    "\n",
    "    Note: If '404 file not found' error returned, function will return without downloading anything.\n",
    "    \n",
    "    Arguments:\n",
    "        url_path: root URL to download from including trailing slash ('/')\n",
    "        filename: filename to download including suffix\n",
    "        save_to: None (to download to root Google Drive GO-BGC directory)\n",
    "                 or directory path\n",
    "        overwrite: False to leave existing files in place\n",
    "                   or True to overwrite existing files\n",
    "        verbose: True to announce progress\n",
    "                 or False to stay silent\n",
    "    \n",
    "    \"\"\"\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    if save_to is None:\n",
    "      save_to = root\n",
    "\n",
    "    try:\n",
    "      if filename in os.listdir(save_to):\n",
    "          if not overwrite:\n",
    "              if verbose: print('>>> File ' + filename + ' already exists. Leaving current version.')\n",
    "              return\n",
    "          else:\n",
    "              if verbose: print('>>> File ' + filename + ' already exists. Overwriting with new version.')\n",
    "\n",
    "      def get_func(url,stream=True):\n",
    "          try:\n",
    "              return requests.get(url,stream=stream,auth=None,verify=False)\n",
    "          except requests.exceptions.ConnectionError as error_tag:\n",
    "              print('Error connecting:',error_tag)\n",
    "              time.sleep(1)\n",
    "              return get_func(url,stream=stream)\n",
    "\n",
    "      response = get_func(url_path + filename,stream=True)\n",
    "\n",
    "      if response.status_code == 404:\n",
    "          if verbose: print('>>> File ' + filename + ' returned 404 error during download.')\n",
    "          return\n",
    "      with open(save_to + filename,'wb') as out_file:\n",
    "          shutil.copyfileobj(response.raw,out_file)\n",
    "      del response\n",
    "      if verbose: print('>>> Successfully downloaded ' + filename + '.')\n",
    "\n",
    "    except:\n",
    "      if verbose: print('>>> An error occurred while trying to download ' + filename + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545821e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and parse GDAC synthetic profile index file\n",
    "def argo_gdac(lat_range=None,lon_range=None,start_date=None,end_date=None,sensors=None,floats=None,\n",
    "              overwrite_index=False,overwrite_profiles=False,skip_download=False,\n",
    "              download_individual_profs=False,save_to=None,verbose=True):\n",
    "  \"\"\" Downloads GDAC Sprof index file, then selects float profiles based on criteria.\n",
    "      Either returns information on profiles and floats (if skip_download=True) or downloads them (if False).\n",
    "\n",
    "      Arguments:\n",
    "          lat_range: None, to select all latitudes\n",
    "                     or [lower, upper] within -90 to 90 (selection is inclusive)\n",
    "          lon_range: None, to select all longitudes\n",
    "                     or [lower, upper] within either -180 to 180 or 0 to 360 (selection is inclusive)\n",
    "                     NOTE: longitude range is allowed to cross -180/180 or 0/360\n",
    "          start_date: None or datetime object\n",
    "          end_date:   None or datetime object\n",
    "          sensors: None, to select profiles with any combination of sensors\n",
    "                   or string or list of strings to specify required sensors\n",
    "                   > note that common options include PRES, TEMP, PSAL, DOXY, CHLA, BBP700,\n",
    "                                                      PH_IN_SITU_TOTAL, and NITRATE\n",
    "          floats: None, to select any floats matching other criteria\n",
    "                  or int or list of ints specifying floats' WMOID numbers\n",
    "          overwrite_index: False to keep existing downloaded GDAC index file, or True to download new index\n",
    "          overwrite_profiles: False to keep existing downloaded profile files, or True to download new files\n",
    "          skip_download: True to skip download and return: (<list of WMOIDs>, <DataFrame of index file subset>,\n",
    "                                                            <list of downloaded filenames [if applicable]>)\n",
    "                         or False to download those profiles\n",
    "          download_individual_profs: False to download single Sprof file containing all profiles for each float\n",
    "                                     or True to download individual profile files for each float\n",
    "          save_to: None to download to Google Drive \"/GO-BGC Workshop/Profiles\" directory\n",
    "                   or string to specify directory path for profile downloads\n",
    "          verbose: True to announce progress, or False to stay silent\n",
    "\n",
    "  \"\"\"\n",
    "  # Paths\n",
    "  url_root = 'https://www.usgodae.org/ftp/outgoing/argo/'\n",
    "  dac_url_root = url_root + 'dac/'\n",
    "  index_filename = 'argo_synthetic-profile_index.txt'\n",
    "  if save_to is None: save_to = root\n",
    "\n",
    "  # Download GDAC synthetic profile index file\n",
    "  download_file(url_root,index_filename,overwrite=overwrite_index)\n",
    "\n",
    "  # Load index file into Pandas DataFrame\n",
    "  gdac_index = pd.read_csv(root + index_filename,delimiter=',',header=8,parse_dates=['date','date_update'],\n",
    "                          date_parser=lambda x: pd.to_datetime(x,format='%Y%m%d%H%M%S'))\n",
    "\n",
    "  # Establish time and space criteria\n",
    "  if lat_range is None:  lat_range = [-90.0,90.0]\n",
    "  if lon_range is None:  lon_range = [-180.0,180.0]\n",
    "  elif lon_range[0] > 180 or lon_range[1] > 180:\n",
    "    if lon_range[0] > 180: lon_range[0] -= 360\n",
    "    if lon_range[1] > 180: lon_range[1] -= 360\n",
    "  if start_date is None: start_date = datetime(1900,1,1)\n",
    "  if end_date is None:   end_date = datetime(2200,1,1)\n",
    "\n",
    "  float_wmoid_regexp = r'[a-z]*/[0-9]*/profiles/[A-Z]*([0-9]*)_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['wmoid'] = gdac_index['file'].str.extract(float_wmoid_regexp).astype(int)\n",
    "  filepath_main_regexp = '([a-z]*/[0-9]*/)profiles/[A-Z]*[0-9]*_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['filepath_main'] = gdac_index['file'].str.extract(filepath_main_regexp)\n",
    "  filepath_regexp = '([a-z]*/[0-9]*/profiles/)[A-Z]*[0-9]*_[0-9]*[A-Z]*.nc'\n",
    "  gdac_index['filepath'] = gdac_index['file'].str.extract(filepath_regexp)\n",
    "  filename_regexp = '[a-z]*/[0-9]*/profiles/([A-Z]*[0-9]*_[0-9]*[A-Z]*.nc)'\n",
    "  gdac_index['filename'] = gdac_index['file'].str.extract(filename_regexp)\n",
    "\n",
    "  # Subset profiles based on time and space criteria\n",
    "  gdac_index_subset = gdac_index.loc[np.logical_and.reduce([gdac_index['latitude'] >= lat_range[0],\n",
    "                                                            gdac_index['latitude'] <= lat_range[1],\n",
    "                                                            gdac_index['date'] >= start_date,\n",
    "                                                            gdac_index['date'] <= end_date]),:]\n",
    "  if lon_range[1] >= lon_range[0]:    # range does not cross -180/180 or 0/360\n",
    "    gdac_index_subset = gdac_index_subset.loc[np.logical_and(gdac_index_subset['longitude'] >= lon_range[0],\n",
    "                                                             gdac_index_subset['longitude'] <= lon_range[1])]\n",
    "  elif lon_range[1] < lon_range[0]:   # range crosses -180/180 or 0/360\n",
    "    gdac_index_subset = gdac_index_subset.loc[np.logical_or(gdac_index_subset['longitude'] >= lon_range[0],\n",
    "                                                            gdac_index_subset['longitude'] <= lon_range[1])]\n",
    "\n",
    "  # If requested, subset profiles using float WMOID criteria\n",
    "  if floats is not None:\n",
    "    if type(floats) is not list: floats = [floats]\n",
    "    gdac_index_subset = gdac_index_subset.loc[gdac_index_subset['wmoid'].isin(floats),:]\n",
    "\n",
    "  # If requested, subset profiles using sensor criteria\n",
    "  if sensors is not None:\n",
    "    if type(sensors) is not list: sensors = [sensors]\n",
    "    for sensor in sensors:\n",
    "      gdac_index_subset = gdac_index_subset.loc[gdac_index_subset['parameters'].str.contains(sensor),:]\n",
    "\n",
    "  # Examine subsetted profiles\n",
    "  wmoids = gdac_index_subset['wmoid'].unique()\n",
    "  wmoid_filepaths = gdac_index_subset['filepath_main'].unique()\n",
    "\n",
    "  # Just return list of floats and DataFrame with subset of index file, or download each profile\n",
    "  if not skip_download:\n",
    "    downloaded_filenames = []\n",
    "    if download_individual_profs:\n",
    "      for p_idx in gdac_index_subset.index:\n",
    "        download_file(dac_url_root + gdac_index_subset.loc[p_idx]['filepath'],\n",
    "                      gdac_index_subset.loc[p_idx]['filename'],\n",
    "                      save_to=save_to,overwrite=overwrite_profiles,verbose=verbose)\n",
    "        downloaded_filenames.append(gdac_index_subset.loc[p_idx]['filename'])\n",
    "    else:\n",
    "      for f_idx, wmoid_filepath in enumerate(wmoid_filepaths):\n",
    "        download_file(dac_url_root + wmoid_filepath,str(wmoids[f_idx]) + '_Sprof.nc',\n",
    "                      save_to=save_to,overwrite=overwrite_profiles,verbose=verbose)\n",
    "        downloaded_filenames.append(str(wmoids[f_idx]) + '_Sprof.nc')\n",
    "    return wmoids, gdac_index_subset, downloaded_filenames\n",
    "  else:\n",
    "    return wmoids, gdac_index_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79415eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> File argo_synthetic-profile_index.txt already exists. Leaving current version.\n",
      ">>> File 4900475_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5900966_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901046_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901048_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901050_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901051_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901052_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901053_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903718_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903721_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903722_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904179_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904185_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904186_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904188_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904396_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904481_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904483_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904598_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904599_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904673_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904677_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904683_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904693_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904695_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904761_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904763_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5904766_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905096_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905098_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905099_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905103_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905371_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905372_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905377_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5905635_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5906315_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5906316_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5906317_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 6903183_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 6903233_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 6903767_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 6903768_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 1901155_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 1901157_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901178_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901646_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901647_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901698_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5901699_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903225_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903242_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903248_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903256_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903260_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903264_Sprof.nc already exists. Leaving current version.\n",
      ">>> File 5903939_Sprof.nc already exists. Leaving current version.\n"
     ]
    }
   ],
   "source": [
    "wmoids, gdac_index, downloaded_filenames \\\n",
    "                  = argo_gdac(lat_range=[-60,-40],lon_range=[-140,-130],start_date=None,end_date=None,sensors=None,floats=None,\n",
    "                                overwrite_index=False,overwrite_profiles=False, skip_download=False,download_individual_profs=False,\n",
    "                                save_to=natl_dir,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016e72f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristenfalcinelli/Documents/Grad School/Research Materials/Mapping/Profiles/Test_Data_BGC/5904673_Sprof.nc\n"
     ]
    }
   ],
   "source": [
    "print((natl_dir + downloaded_filenames[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c431d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
